{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1hd2kT9__RkXWymIcD7Ef6J4E4QDEj_8S",
      "authorship_tag": "ABX9TyNQaqWnDCpZ6Dnyq5ch2o/M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZungLV/AI/blob/main/Train_Face.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from os import listdir\n",
        "from numpy import asarray, save\n",
        "from keras.utils import load_img, img_to_array, to_categorical\n",
        "\n",
        "folder = '/content/drive/MyDrive/Datasets AI/'\n",
        "photos,labels = list(), list()\n",
        "\n",
        "for file in listdir(data):\n",
        "  output=0\n",
        "  if file.startswith('Dung'):\n",
        "    output = 1\n",
        "  if file.startswith('Hanh'):\n",
        "    output = 2\n",
        "  if file.startswith('Truc'):\n",
        "    output = 3\n",
        "  if file.startswith('Phat'):\n",
        "    output = 4\n",
        "  if file.startswith('Phuc'):\n",
        "    output = 5\n",
        "  photo = load_img(folder + file,target_size=(192,257))\n",
        "  photo = img_to_array(photo)\n",
        "  photos.append(photo)\n",
        "  labels.append(output)\n",
        "\n",
        "photos = asarray(photos)\n",
        "labels = asarray(labels)\n",
        "labels = to_categorical(labels)\n",
        "\n",
        "print(photos.shape,labels.shape)\n",
        "print(photos)\n",
        "\n",
        "save('/content/drive/MyDrive/Colab Notebooks/Test 1 AI/AIdata_photo.npy',photos)\n",
        "save('/content/drive/MyDrive/Colab Notebooks/Test 1 AI/AIdata_label.npy',labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DaPedqGoE73",
        "outputId": "00a70ace-6565-4b71-8087-df5c94ea570f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(577, 192, 257, 3) (577, 6)\n",
            "[[[[153. 155. 154.]\n",
            "   [155. 155. 155.]\n",
            "   [154. 154. 154.]\n",
            "   ...\n",
            "   [ 50.  50.  52.]\n",
            "   [ 54.  54.  54.]\n",
            "   [ 54.  54.  52.]]\n",
            "\n",
            "  [[154. 156. 155.]\n",
            "   [155. 155. 155.]\n",
            "   [154. 154. 154.]\n",
            "   ...\n",
            "   [ 38.  38.  38.]\n",
            "   [ 50.  50.  50.]\n",
            "   [ 57.  57.  55.]]\n",
            "\n",
            "  [[156. 158. 157.]\n",
            "   [154. 156. 155.]\n",
            "   [153. 153. 153.]\n",
            "   ...\n",
            "   [ 30.  30.  30.]\n",
            "   [ 48.  48.  48.]\n",
            "   [ 49.  49.  49.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[166. 167. 172.]\n",
            "   [168. 169. 174.]\n",
            "   [164. 165. 169.]\n",
            "   ...\n",
            "   [ 61.  61.  61.]\n",
            "   [ 58.  56.  57.]\n",
            "   [ 58.  56.  57.]]\n",
            "\n",
            "  [[168. 168. 176.]\n",
            "   [167. 167. 175.]\n",
            "   [165. 166. 171.]\n",
            "   ...\n",
            "   [ 59.  59.  59.]\n",
            "   [ 58.  56.  57.]\n",
            "   [ 58.  56.  57.]]\n",
            "\n",
            "  [[166. 166. 174.]\n",
            "   [166. 166. 174.]\n",
            "   [165. 166. 171.]\n",
            "   ...\n",
            "   [ 57.  57.  57.]\n",
            "   [ 54.  54.  54.]\n",
            "   [ 57.  55.  56.]]]\n",
            "\n",
            "\n",
            " [[[154. 156. 155.]\n",
            "   [155. 157. 156.]\n",
            "   [156. 156. 156.]\n",
            "   ...\n",
            "   [ 49.  51.  50.]\n",
            "   [ 56.  56.  56.]\n",
            "   [ 53.  52.  50.]]\n",
            "\n",
            "  [[153. 155. 154.]\n",
            "   [155. 157. 156.]\n",
            "   [152. 152. 152.]\n",
            "   ...\n",
            "   [ 43.  43.  43.]\n",
            "   [ 50.  50.  50.]\n",
            "   [ 52.  51.  49.]]\n",
            "\n",
            "  [[153. 155. 154.]\n",
            "   [153. 155. 154.]\n",
            "   [153. 153. 153.]\n",
            "   ...\n",
            "   [ 30.  30.  30.]\n",
            "   [ 47.  47.  47.]\n",
            "   [ 48.  48.  46.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[166. 166. 176.]\n",
            "   [167. 167. 177.]\n",
            "   [166. 167. 172.]\n",
            "   ...\n",
            "   [ 61.  61.  61.]\n",
            "   [ 60.  60.  60.]\n",
            "   [ 57.  57.  57.]]\n",
            "\n",
            "  [[166. 166. 176.]\n",
            "   [166. 166. 174.]\n",
            "   [165. 166. 170.]\n",
            "   ...\n",
            "   [ 62.  62.  62.]\n",
            "   [ 57.  57.  57.]\n",
            "   [ 56.  56.  56.]]\n",
            "\n",
            "  [[164. 164. 174.]\n",
            "   [166. 166. 174.]\n",
            "   [166. 167. 171.]\n",
            "   ...\n",
            "   [ 55.  55.  55.]\n",
            "   [ 55.  55.  55.]\n",
            "   [ 55.  55.  55.]]]\n",
            "\n",
            "\n",
            " [[[153. 155. 154.]\n",
            "   [154. 156. 155.]\n",
            "   [155. 155. 155.]\n",
            "   ...\n",
            "   [ 45.  45.  45.]\n",
            "   [ 53.  53.  53.]\n",
            "   [ 54.  54.  52.]]\n",
            "\n",
            "  [[152. 154. 153.]\n",
            "   [154. 156. 155.]\n",
            "   [155. 155. 155.]\n",
            "   ...\n",
            "   [ 44.  44.  44.]\n",
            "   [ 51.  51.  51.]\n",
            "   [ 48.  48.  46.]]\n",
            "\n",
            "  [[151. 155. 154.]\n",
            "   [153. 155. 154.]\n",
            "   [154. 156. 155.]\n",
            "   ...\n",
            "   [ 32.  32.  32.]\n",
            "   [ 48.  48.  48.]\n",
            "   [ 49.  49.  47.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[166. 166. 174.]\n",
            "   [169. 170. 175.]\n",
            "   [166. 167. 169.]\n",
            "   ...\n",
            "   [ 64.  64.  64.]\n",
            "   [ 59.  59.  59.]\n",
            "   [ 57.  57.  57.]]\n",
            "\n",
            "  [[169. 170. 175.]\n",
            "   [170. 171. 175.]\n",
            "   [164. 165. 167.]\n",
            "   ...\n",
            "   [ 61.  61.  61.]\n",
            "   [ 56.  56.  56.]\n",
            "   [ 57.  57.  57.]]\n",
            "\n",
            "  [[167. 168. 172.]\n",
            "   [168. 169. 171.]\n",
            "   [165. 166. 168.]\n",
            "   ...\n",
            "   [ 57.  57.  57.]\n",
            "   [ 57.  57.  57.]\n",
            "   [ 56.  56.  56.]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[198. 212. 215.]\n",
            "   [201. 212. 216.]\n",
            "   [202. 213. 217.]\n",
            "   ...\n",
            "   [225. 228. 235.]\n",
            "   [229. 229. 237.]\n",
            "   [228. 228. 236.]]\n",
            "\n",
            "  [[201. 210. 215.]\n",
            "   [203. 212. 217.]\n",
            "   [201. 210. 215.]\n",
            "   ...\n",
            "   [226. 229. 234.]\n",
            "   [226. 229. 236.]\n",
            "   [226. 229. 236.]]\n",
            "\n",
            "  [[200. 207. 213.]\n",
            "   [201. 208. 214.]\n",
            "   [204. 211. 217.]\n",
            "   ...\n",
            "   [225. 230. 234.]\n",
            "   [225. 230. 234.]\n",
            "   [225. 230. 234.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[106. 114. 116.]\n",
            "   [ 92.  96.  97.]\n",
            "   [ 84.  84.  84.]\n",
            "   ...\n",
            "   [255. 245. 233.]\n",
            "   [255. 248. 235.]\n",
            "   [255. 252. 238.]]\n",
            "\n",
            "  [[108. 119. 121.]\n",
            "   [106. 116. 118.]\n",
            "   [108. 113. 117.]\n",
            "   ...\n",
            "   [254. 244. 232.]\n",
            "   [255. 247. 234.]\n",
            "   [255. 251. 237.]]\n",
            "\n",
            "  [[125. 140. 143.]\n",
            "   [132. 147. 150.]\n",
            "   [139. 153. 156.]\n",
            "   ...\n",
            "   [252. 242. 230.]\n",
            "   [254. 246. 233.]\n",
            "   [253. 247. 233.]]]\n",
            "\n",
            "\n",
            " [[[240. 240. 240.]\n",
            "   [234. 234. 234.]\n",
            "   [239. 239. 239.]\n",
            "   ...\n",
            "   [239. 239. 239.]\n",
            "   [240. 240. 240.]\n",
            "   [239. 239. 239.]]\n",
            "\n",
            "  [[235. 235. 235.]\n",
            "   [236. 236. 236.]\n",
            "   [238. 238. 238.]\n",
            "   ...\n",
            "   [239. 239. 239.]\n",
            "   [239. 239. 239.]\n",
            "   [241. 241. 241.]]\n",
            "\n",
            "  [[238. 238. 238.]\n",
            "   [238. 238. 238.]\n",
            "   [237. 237. 237.]\n",
            "   ...\n",
            "   [238. 238. 238.]\n",
            "   [240. 240. 240.]\n",
            "   [240. 240. 240.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[142.  83.  89.]\n",
            "   [140.  83.  89.]\n",
            "   [145.  88.  94.]\n",
            "   ...\n",
            "   [201. 152. 122.]\n",
            "   [202. 153. 123.]\n",
            "   [201. 152. 122.]]\n",
            "\n",
            "  [[146.  86.  88.]\n",
            "   [149.  89.  91.]\n",
            "   [145.  90.  93.]\n",
            "   ...\n",
            "   [201. 155. 122.]\n",
            "   [199. 153. 120.]\n",
            "   [198. 152. 119.]]\n",
            "\n",
            "  [[150.  89.  88.]\n",
            "   [154.  94.  94.]\n",
            "   [140.  92.  90.]\n",
            "   ...\n",
            "   [196. 149. 123.]\n",
            "   [195. 148. 122.]\n",
            "   [196. 149. 123.]]]\n",
            "\n",
            "\n",
            " [[[204. 211. 219.]\n",
            "   [203. 210. 216.]\n",
            "   [202. 207. 210.]\n",
            "   ...\n",
            "   [229. 228. 236.]\n",
            "   [225. 228. 237.]\n",
            "   [222. 226. 235.]]\n",
            "\n",
            "  [[204. 211. 217.]\n",
            "   [203. 211. 214.]\n",
            "   [203. 208. 211.]\n",
            "   ...\n",
            "   [228. 229. 234.]\n",
            "   [225. 230. 236.]\n",
            "   [224. 231. 237.]]\n",
            "\n",
            "  [[203. 211. 214.]\n",
            "   [204. 212. 215.]\n",
            "   [203. 211. 213.]\n",
            "   ...\n",
            "   [227. 232. 236.]\n",
            "   [223. 231. 234.]\n",
            "   [220. 230. 232.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[111. 112. 114.]\n",
            "   [103. 102. 108.]\n",
            "   [ 70.  63.  71.]\n",
            "   ...\n",
            "   [255. 245. 233.]\n",
            "   [255. 248. 235.]\n",
            "   [254. 251. 236.]]\n",
            "\n",
            "  [[110. 122. 120.]\n",
            "   [109. 119. 121.]\n",
            "   [108. 115. 123.]\n",
            "   ...\n",
            "   [255. 245. 233.]\n",
            "   [255. 248. 235.]\n",
            "   [255. 252. 235.]]\n",
            "\n",
            "  [[123. 136. 144.]\n",
            "   [128. 141. 149.]\n",
            "   [130. 143. 149.]\n",
            "   ...\n",
            "   [255. 246. 231.]\n",
            "   [255. 248. 230.]\n",
            "   [253. 250. 231.]]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIFJM6RW2h1b",
        "outputId": "04d97bc2-d111-4724-d0e8-a831a9b272a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "size of photos:   (577, 192, 257, 3)\n",
            "size of label :  (577, 6)\n",
            "size of photo_train:  (461, 192, 257, 3)\n",
            "size of photo_test: (116, 192, 257, 3)\n",
            "size of label_train (461, 6)\n",
            "size of label_test: (116, 6)\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "photo_url  = '/content/drive/MyDrive/Colab Notebooks/Test 1 AI/AIdata_photo.npy'\n",
        "labels_url = '/content/drive/MyDrive/Colab Notebooks/Test 1 AI/AIdata_label.npy'\n",
        "\n",
        "photos = np.load(photo_url)\n",
        "print(\"size of photos:  \",photos.shape)\n",
        "labels = np.load(labels_url)\n",
        "print(\"size of label : \",labels.shape)\n",
        "\n",
        "photo_train,photo_test,label_train,label_test = train_test_split(photos,labels, test_size = 0.2)\n",
        "\n",
        "print(\"size of photo_train: \",photo_train.shape)\n",
        "print(\"size of photo_test:\", photo_test.shape)\n",
        "print(\"size of label_train\", label_train.shape)\n",
        "print(\"size of label_test:\", label_test.shape)\n",
        "\n",
        "print(type(label_train))\n",
        "print(type(photo_train))\n",
        "\n",
        "photo_train = photo_train.astype('float32')/255\n",
        "photo_test  = photo_test.astype('float32')/255\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, Dense, LeakyReLU, MaxPooling2D, Flatten, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import categorical_crossentropy\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size = (3,3), activation = 'relu', input_shape = (192,257,3), padding = 'same' ))\n",
        "model.add(LeakyReLU(alpha =0.1))\n",
        "model.add(MaxPooling2D((2,2), padding =\"same\" ))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64,(3,3), activation = 'relu', padding ='same'))\n",
        "model.add(LeakyReLU(alpha = 0.1))\n",
        "model.add(MaxPooling2D((2,2), padding = 'same'))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation = 'relu'))\n",
        "model.add(LeakyReLU(alpha = 0.1))\n",
        "model.add(Dense(6,activation = 'softmax'))\n",
        "\n",
        "model.compile(loss = categorical_crossentropy , optimizer = Adam(), metrics = ['accuracy'])\n",
        "model.summary()\n",
        "train = model.fit(photo_train,label_train, batch_size = 64, epochs = 10)\n",
        "loss,acc = model.evaluate(photo_test,label_test)\n",
        "print(\"Do chinh xac:  \",acc)\n",
        "print(\"Do mat mat:  \",loss)\n",
        "model.save('AIdata.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpkvb85s3ZWL",
        "outputId": "7aa05c17-4fe0-4596-9688-252b38b3b1c3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 192, 257, 32)      896       \n",
            "                                                                 \n",
            " leaky_re_lu_9 (LeakyReLU)   (None, 192, 257, 32)      0         \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 96, 129, 32)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 96, 129, 32)       0         \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 96, 129, 64)       18496     \n",
            "                                                                 \n",
            " leaky_re_lu_10 (LeakyReLU)  (None, 96, 129, 64)       0         \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 48, 65, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 48, 65, 64)        0         \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 199680)            0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 64)                12779584  \n",
            "                                                                 \n",
            " leaky_re_lu_11 (LeakyReLU)  (None, 64)                0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 6)                 390       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12,799,366\n",
            "Trainable params: 12,799,366\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "8/8 [==============================] - 2s 147ms/step - loss: 7.4405 - accuracy: 0.4469\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 1s 152ms/step - loss: 1.4765 - accuracy: 0.7440\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 1s 154ms/step - loss: 0.8728 - accuracy: 0.7852\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 1s 149ms/step - loss: 0.4699 - accuracy: 0.9111\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 1s 143ms/step - loss: 0.1586 - accuracy: 0.9566\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 1s 146ms/step - loss: 0.0933 - accuracy: 0.9631\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 1s 145ms/step - loss: 0.0509 - accuracy: 0.9848\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 1s 144ms/step - loss: 0.0334 - accuracy: 0.9892\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 1s 145ms/step - loss: 0.0185 - accuracy: 0.9935\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 1s 145ms/step - loss: 0.0100 - accuracy: 0.9978\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.0287 - accuracy: 0.9828\n",
            "Do chinh xac:   0.982758641242981\n",
            "Do mat mat:   0.028688788414001465\n"
          ]
        }
      ]
    }
  ]
}